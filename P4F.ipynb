{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from Lec7sbs import StepByStep\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms.functional import  rotate, vflip, hflip\n",
    "from torchvision.transforms import Compose, ToTensor, RandomHorizontalFlip, RandomVerticalFlip, RandomRotation, ToPILImage, Normalize\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "Images = np.load('./X.npy')\n",
    "labels = np.load('./y.npy')\n",
    "X=  torch.as_tensor(Images/255.0).float()\n",
    "y=  torch.as_tensor(labels).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class TransformedTensorDataset(Dataset):\n",
    "    def __init__(self, x, y, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    " \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    " \n",
    "        return x, self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True)\n",
    "transform = Normalize(mean=(.5,), std=(.5,))\n",
    "train_dataset = TransformedTensorDataset(X_train, y_train, transform=transform)\n",
    "val_dataset = TransformedTensorDataset(X_test, y_test, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240, 1, 20, 20])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate loaders\n",
    "def CNNModel(num_layers: int, num_filters: [], filter_size: [], padding: []):\n",
    "    assert len(num_filters) == num_layers\n",
    "    assert len(filter_size) == num_layers\n",
    "    assert len(padding) == num_layers\n",
    "    x = (20 -filter_size[0] + 2 * padding[0]) + 1\n",
    "    y = (20 -filter_size[0] + 2 * padding[0]) + 1\n",
    "    x = x // 2  # Assuming max pool with kernel size 2\n",
    "    y = y // 2\n",
    "    cnn_model = nn.Sequential()\n",
    "    cnn_model.add_module('conv_1', nn.Conv2d(in_channels=1,\n",
    "                                             out_channels=num_filters[0],\n",
    "                                             kernel_size=filter_size[0],\n",
    "                                             padding=padding[0]))\n",
    "    cnn_model.add_module('relu_1', nn.ReLU())\n",
    "    cnn_model.add_module('maxpool_1', nn.MaxPool2d(kernel_size=2))\n",
    "    for i in range(1, num_layers):\n",
    "        cnn_model.add_module('conv_'+str(i+1), nn.Conv2d(in_channels=num_filters[i-1], out_channels=num_filters[i], kernel_size=filter_size[i], padding=padding[i]))\n",
    "        cnn_model.add_module('relu_'+str(i+1), nn.ReLU())\n",
    "        cnn_model.add_module('pool_' + str(i+1), nn.MaxPool2d(kernel_size=2))\n",
    "        cnn_model.add_module('dropout' + str(i+1), nn.Dropout(p=0.5))\n",
    "        x = (x - filter_size[i] + 2 * padding[i]) + 1  # Assuming stride=1\n",
    "        y = (y - filter_size[i] + 2 * padding[i]) + 1\n",
    "        x = x // 2  # Assuming max pool with kernel size 2\n",
    "        y = y // 2\n",
    "    cnn_model.add_module('flat', nn.Flatten())\n",
    "    cnn_model.add_module('lin', nn.Linear(x*y*num_filters[-1], 3))\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CNNModel(2,[16,32], [2,2], [0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 16, 2, 2], expected input[60, 1, 20, 20] to have 16 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/mariavictoriadacostarivas/Documents/MECE/655/P4/P4F.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mariavictoriadacostarivas/Documents/MECE/655/P4/P4F.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a(X_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TFG/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TFG/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TFG/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TFG/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TFG/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 16, 2, 2], expected input[60, 1, 20, 20] to have 16 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "a(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariavictoriadacostarivas/opt/anaconda3/envs/TFG/lib/python3.8/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "num_layers = [1,2,3,4]\n",
    "num_filters = [[16],[32],[64], [16, 32], [16, 64], [32, 64], [32, 128], [16, 32, 64], [16,32,64, 16], [16, 32, 64, 128]]\n",
    "filter_size = [[2], [3], [5], [2,2], [3, 3],[5,5], [3,3,3], [5,5,5], [3,5,3], [5, 5, 3], [3, 3, 3, 3], [5,5,3,3], [5,5,5,5]]\n",
    "padding = [[0], [1], [0, 0],[1,1], [1, 1, 1], [0,0,0], [1, 1, 1, 1], [0,0,0,0]]\n",
    "cnn_models = []\n",
    "for i in range(len(num_layers)):\n",
    "    for j in range(len(num_filters)):\n",
    "        if len(num_filters[j]) != num_layers[i]:\n",
    "            continue\n",
    "        for k in range(len(filter_size)):\n",
    "            if len(filter_size[k]) != num_layers[i]:\n",
    "                continue\n",
    "            for l in range(len(padding)):\n",
    "                if len(padding[l]) != num_layers[i]:\n",
    "                    continue\n",
    "                cnn_models.append(CNNModel(num_layers[i], num_filters[j], filter_size[k], padding[l]))\n",
    "                cnn_models[-1].name = 'CNNModel_' + str(num_layers[i])+ \"_\" + str(num_filters[j]) +\"_\"+ str(filter_size[k])+\"_\" + str(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNModel_1_[16]_[2]_0\n",
      "{'Config': 'CNNModel_1_[16]_[2]_0', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 3971, 'T': 1.2916666666666666e-05, 'Cost': 0.05129208333333333, 'minBC': 0.16518747713416815}\n",
      "CNNModel_1_[16]_[2]_1\n",
      "{'Config': 'CNNModel_1_[16]_[2]_1', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 4883, 'T': 2.1133333333333333e-05, 'Cost': 0.10319406666666667, 'minBC': 0.15783592375616232}\n",
      "CNNModel_1_[16]_[3]_0\n",
      "{'Config': 'CNNModel_1_[16]_[3]_0', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 4051, 'T': 1.615e-05, 'Cost': 0.06542365, 'minBC': 0.14906906600420675}\n",
      "CNNModel_1_[16]_[3]_1\n",
      "{'Config': 'CNNModel_1_[16]_[3]_1', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 4963, 'T': 2.0666666666666666e-05, 'Cost': 0.10256866666666667, 'minBC': 0.1622285097837448}\n",
      "CNNModel_1_[16]_[5]_0\n",
      "{'Config': 'CNNModel_1_[16]_[5]_0', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 3491, 'T': 2.5133333333333332e-05, 'Cost': 0.08774046666666667, 'minBC': 0.1548525644466281}\n",
      "CNNModel_1_[16]_[5]_1\n",
      "{'Config': 'CNNModel_1_[16]_[5]_1', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 4307, 'T': 2.9083333333333333e-05, 'Cost': 0.12526191666666667, 'minBC': 0.1555834769581755}\n",
      "CNNModel_1_[32]_[2]_0\n",
      "{'Config': 'CNNModel_1_[32]_[2]_0', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 7939, 'T': 2.7166666666666665e-05, 'Cost': 0.21567616666666667, 'minBC': 0.1505198460072279}\n",
      "CNNModel_1_[32]_[2]_1\n",
      "{'Config': 'CNNModel_1_[32]_[2]_1', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 9763, 'T': 3.185e-05, 'Cost': 0.31095155, 'minBC': 0.1588160302489996}\n",
      "CNNModel_1_[32]_[3]_0\n",
      "{'Config': 'CNNModel_1_[32]_[3]_0', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 8099, 'T': 3.1316666666666664e-05, 'Cost': 0.2536336833333333, 'minBC': 0.156293421673278}\n",
      "CNNModel_1_[32]_[3]_1\n",
      "{'Config': 'CNNModel_1_[32]_[3]_1', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 9923, 'T': 3.725e-05, 'Cost': 0.36963175, 'minBC': 0.1533259516581893}\n",
      "CNNModel_1_[32]_[5]_0\n",
      "{'Config': 'CNNModel_1_[32]_[5]_0', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 6979, 'T': 3.851666666666667e-05, 'Cost': 0.2688078166666667, 'minBC': 0.15245677654941878}\n",
      "CNNModel_1_[32]_[5]_1\n",
      "{'Config': 'CNNModel_1_[32]_[5]_1', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 8611, 'T': 5.191666666666667e-05, 'Cost': 0.4470544166666667, 'minBC': 0.15844294056296349}\n",
      "CNNModel_1_[64]_[2]_0\n",
      "{'Config': 'CNNModel_1_[64]_[2]_0', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 15875, 'T': 0.0001471, 'Cost': 2.3352125, 'minBC': 0.1553071311985453}\n",
      "CNNModel_1_[64]_[2]_1\n",
      "{'Config': 'CNNModel_1_[64]_[2]_1', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 19523, 'T': 7.631666666666666e-05, 'Cost': 1.4899302833333332, 'minBC': 0.17721456941217184}\n",
      "CNNModel_1_[64]_[3]_0\n",
      "{'Config': 'CNNModel_1_[64]_[3]_0', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 16195, 'T': 6.458333333333334e-05, 'Cost': 1.0459270833333334, 'minBC': 0.163537273183465}\n",
      "CNNModel_1_[64]_[3]_1\n",
      "{'Config': 'CNNModel_1_[64]_[3]_1', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 19843, 'T': 7.405e-05, 'Cost': 1.46937415, 'minBC': 0.1473198694487413}\n",
      "CNNModel_1_[64]_[5]_0\n",
      "{'Config': 'CNNModel_1_[64]_[5]_0', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 13955, 'T': 0.00010941666666666667, 'Cost': 1.5269095833333333, 'minBC': 0.15692656316484013}\n",
      "CNNModel_1_[64]_[5]_1\n",
      "{'Config': 'CNNModel_1_[64]_[5]_1', 'E95': 0, 'E90': 0, 'E80': 0, 'E70': 0, 'P': 17219, 'T': 0.00010941666666666667, 'Cost': 1.8840455833333334, 'minBC': 0.17378221219405532}\n",
      "CNNModel_2_[16, 32]_[2, 2]_2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 16, 2, 2], expected input[10, 1, 20, 20] to have 16 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/mariavictoriadacostarivas/Documents/MECE/655/P4/P4F.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariavictoriadacostarivas/Documents/MECE/655/P4/P4F.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariavictoriadacostarivas/Documents/MECE/655/P4/P4F.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mariavictoriadacostarivas/Documents/MECE/655/P4/P4F.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariavictoriadacostarivas/Documents/MECE/655/P4/P4F.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariavictoriadacostarivas/Documents/MECE/655/P4/P4F.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m train_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TFG/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TFG/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TFG/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TFG/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TFG/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 16, 2, 2], expected input[10, 1, 20, 20] to have 16 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
    "lr = 1e-2\n",
    "# Defines a BCE without logits loss function (uses probabilities)\n",
    "n_epochs = 100\n",
    "\"\"\"\n",
    "You should have an automated Python program that trains each model for around 20\n",
    "epochs. You can suppress plotting the losses to avoid cluttering your report. Instead, all\n",
    "we care about is the following summary out of each model:\n",
    "o minBC: minimum validation BC loss at the end of training. Totally ignore the\n",
    "training loss. The validation seems to be more stable.\n",
    "o E95: number of epochs it took to reach 95% accuracy. If your model has not\n",
    "reached it, make this number None.\n",
    "o E90: number… to reach 90%\n",
    "o E80: number… to reach 80%\n",
    "o E70: number… to reach 70%\n",
    "o P: number of parameters in the model\n",
    "o T: evaluation time for one input. You can determine that by evaluating 100\n",
    "consecutive entries and dividing it by 100, etc. to eliminate measurement noise.\n",
    "o Cost: The cost of the model. This is a figure-of-merit that determines how\n",
    "expensive it is to use the model. Calculate it by 𝐶𝑜𝑠𝑡 = 𝑃 ∗ 𝑇. Since increasing 𝑃\n",
    "will very likely decrease 𝑇, it is not necessarily obvious which model will have\n",
    "the lowest Cost. It is common practice to use such metrics; for example, in chip\n",
    "design, Power*Delay or Area*Delay products are commonly used to study how\n",
    "the power consumption can be traded-off against delay (i.e., chip speed), etc.\n",
    "\"\"\"\n",
    "reports = []\n",
    "for model in cnn_models:\n",
    "    print(model.name)\n",
    "    report = {\"Config\":model.name ,\n",
    "              \"E95\": None, \"E90\": None, \"E80\": None, \"E70\": None, \"P\": None, \"T\": None, \"Cost\": None, \"minBC\": None}\n",
    "    min_val_loss = float('inf')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    report[\"P\"] = sum(p.numel() for p in model.parameters())\n",
    "    loss_fn =nn.CrossEntropyLoss(reduction='mean')\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = []\n",
    "        val_loss = []\n",
    "        for data,target in train_loader:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            for data,target in test_loader:\n",
    "                model.eval()\n",
    "                output = model(data)\n",
    "                loss_val = loss_fn(output, target)\n",
    "                val_loss.append(loss_val.item())\n",
    "            output = model(X_test)\n",
    "            predicted_classes = torch.argmax(output, dim=1)\n",
    "            accuracy = (predicted_classes == y_test).sum().item()\n",
    "            accuracy /= len(target)\n",
    "            if accuracy >= 0.7 and report[\"E70\"] is None:\n",
    "                report[\"E70\"] = epoch\n",
    "            if accuracy >= 0.8 and report[\"E80\"] is None:\n",
    "                report[\"E80\"] = epoch\n",
    "            if accuracy >= 0.9 and report[\"E90\"] is None:\n",
    "                report[\"E90\"] = epoch\n",
    "            if accuracy >= 0.95 and report[\"E95\"] is None:\n",
    "                report[\"E95\"] = epoch\n",
    "        train_loss_val = np.mean(train_loss)\n",
    "        val_loss_val = np.mean(val_loss)\n",
    "        if val_loss_val < min_val_loss:\n",
    "            min_val_loss = val_loss_val\n",
    "        #print(f\" Epoch {epoch}: train loss {train_loss_val}, val loss {val_loss_val}\")\n",
    "    start_t = datetime.now()\n",
    "    output = model(X_test)\n",
    "    report[\"T\"] = (datetime.now() - start_t).total_seconds() / X_test.shape[0]\n",
    "    report[\"minBC\"] = min_val_loss\n",
    "    report[\"Cost\"] = report[\"P\"] * report[\"T\"]\n",
    "    print(report)\n",
    "    reports.append(report)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
